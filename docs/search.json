[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Combined Cycle Power Plant\n\n\n\nimage.png\n\n\nEl conjunto de datos contiene 9568 puntos de datos recopilados de una Planta de Energía de Ciclo Combinado (CCPP) durante 6 años (2006-2011), cuando la planta de energía funcionaba a plena carga. Las características consisten en las variables ambientales promedio por hora: Temperatura (AT), Presión Ambiental (AP), Humedad Relativa (RH) y Vacío de Escape (V), para predecir la producción neta de energía eléctrica por hora (PE) de la planta.\nUna planta de energía de ciclo combinado (CCPP) se compone de turbinas de gas (GT), turbinas de vapor (ST) y generadores de vapor por recuperación de calor. En una CCPP, la electricidad se genera mediante turbinas de gas y vapor, que se combinan en un solo ciclo, y se transfiere de una turbina a otra. Mientras que el Vacío se recoge de la turbina de vapor y tiene un efecto sobre ella, las otras tres variables ambientales afectan el rendimiento de la turbina de gas.\n\n\nSe realiza un descripción de las variables y de la variable objetivo (Target)\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\n\n\n\n\nAT\nFeature\nContinuous\nen el rango 1.81°C and 37.11°C\nC\n\n\nV\nFeature\nContinuous\nen el rango 25.36-81.56 cm Hg\ncm Hg\n\n\nAP\nFeature\nContinuous\nen el rango 992.89-1033.30 milibar\nmilibar\n\n\nRH\nFeature\nContinuous\nen el rango 25.56% a 100.16%\n%\n\n\nPE\nTarget\nContinuous\n420.26-495.76 MW\nMW\n\n\n\n\n\nCode\n# Importamos los paquetes necesarios\nfrom sklearn.linear_model import LinearRegression # Regresión lineal con scikit-learn\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\nimport altair as alt\nimport pandas as pd\n\nMW_df = pd.read_csv(r'data\\Ciclo_conbinado.csv', delimiter=';', encoding='latin-1')\n\nMW_df.head()\n\n\n\n\n\n\n\n\n\nAT\nV\nAP\nRH\nPE\n\n\n\n\n0\n14.96\n41.76\n1024.07\n73.17\n463.26\n\n\n1\n25.18\n62.96\n1020.04\n59.08\n444.37\n\n\n2\n5.11\n39.40\n1012.16\n92.14\n488.56\n\n\n3\n20.86\n57.32\n1010.24\n76.64\n446.48\n\n\n4\n10.82\n37.50\n1009.23\n96.62\n473.90\n\n\n\n\n\n\n\nPrincipales estadisticas:\n\n\nCode\nMW_df.describe()\n\n\n\n\n\n\n\n\n\nAT\nV\nAP\nRH\nPE\n\n\n\n\ncount\n9568.000000\n9568.000000\n9568.000000\n9568.000000\n9568.000000\n\n\nmean\n19.651231\n54.305804\n1013.259078\n73.308978\n454.365009\n\n\nstd\n7.452473\n12.707893\n5.938784\n14.600269\n17.066995\n\n\nmin\n1.810000\n25.360000\n992.890000\n25.560000\n420.260000\n\n\n25%\n13.510000\n41.740000\n1009.100000\n63.327500\n439.750000\n\n\n50%\n20.345000\n52.080000\n1012.940000\n74.975000\n451.550000\n\n\n75%\n25.720000\n66.540000\n1017.260000\n84.830000\n468.430000\n\n\nmax\n37.110000\n81.560000\n1033.300000\n100.160000\n495.760000\n\n\n\n\n\n\n\nMatriz de correlación entre las diferentes variables\n\n\nCode\nmatriz_correlacion = MW_df.corr(method='pearson')\n\nplt.figure(figsize=(10, 8))\n\nsns.heatmap(\n    matriz_correlacion,\n    annot=True,          # Muestra el valor de correlación en cada celda\n    fmt='.2f',           # Dos decimales\n    cmap='coolwarm',     # Esquema de color divergente (rojo para positivo, azul para negativo)\n    linewidths=.5,       \n    cbar_kws={'label': 'Coeficiente de Correlación'} \n)\n\nplt.title('Matriz de Correlación de Combined Cycle Power Plant', fontsize=16)\nplt.show()\n\n\n\n\n\n\n\n\n\nVariables con una alta correlación positiva. Es decir, mientras una variable aumenta la otra variable aumenta:\n\nV vs AT (0.84)\n\nVariables con una alta correlación negativa. Es decir, mientras una variable aumenta la otra variable disminuye:\n\nRH vs AT (-0.54)\nAP vs AT (-0.51)\n\nVariables con una alta correlación con la variable objetivo PE (MW):\n\nPE vs AT (-0.95) negativa\nPE vs V (-0.87) negativa\nAP vs PE (0.52) positiva\n\n\n\nCode\nalt.data_transformers.disable_max_rows()\n\nnumerical_columns = MW_df.select_dtypes('number').columns.tolist()\n\nalt.Chart(MW_df).mark_rect().encode(\n    alt.X(alt.repeat('column'),type='quantitative',bin=alt.Bin(maxbins=30)),\n    alt.Y(alt.repeat('row'),type='quantitative',bin=alt.Bin(maxbins=30)),\n    alt.Color('count()'),\n    alt.Tooltip('count()')\n).properties(\n    width=100,\n    height=100\n).repeat(\n    column=numerical_columns,\n    row=numerical_columns\n).resolve_scale(\n    color='independent'\n)\n\n\n\n\n\n\n\n\nSe observa con mayor claridad en el Heatmap Matrix las relaciones presentadas en la matriz de correlación.\nEspecialmente, PE vs AT (-0.95), V vs AT (0.84) y PE vs V (-0.87).\n\n\nCode\nheatmap_scatter = alt.Chart(MW_df).mark_rect().encode(\n    alt.X('AT', bin=alt.Bin(maxbins=100)),\n    alt.Y('PE', bin=alt.Bin(maxbins=100)),\n    alt.Color('count()'),\n    alt.Tooltip('count()')\n).properties(\n    title=\"Binned Heatmap: AT vs PE\"\n)\n\nheatmap_scatter\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfor col in MW_df.columns:\n    MW_df[col] = pd.to_numeric(MW_df[col], errors='coerce')\nMW_df = MW_df.dropna()\n\n\n\n\nCode\nfrom sklearn.model_selection import train_test_split\n\nX = MW_df.drop('PE', axis=1) # Predictoras\ny = MW_df['PE']  \n\n\n# Dividimos directamente, usando el 70% para entrenamiento y 30% para prueba.\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.3, # 30% para prueba\n    random_state=42\n)\n\nprint(f'Dimensiones de X_train (Entrenamiento): {X_train.shape}')\nprint(f'Dimensiones de X_test (Prueba): {X_test.shape}\\n')\n\n\nDimensiones de X_train (Entrenamiento): (6697, 4)\nDimensiones de X_test (Prueba): (2871, 4)\n\n\n\n\n\n\n\n\nCode\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Pipeline: Estandarización de los datos y Regresión Lineal\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('regressor', LinearRegression())\n])\n\n# Entrenamiento del modelo con el conjunto de ENTRENAMIENTO\npipe.fit(X_train, y_train)\n\n# Evaluación en el Conjunto de PRUEBA (X_test)\ny_pred_test = pipe.predict(X_test)\n\n\n\n\n\nSe realizara una nueva predicción con nuevos datos nunca vistos:\n\n\n\nVariable\nValor\n\n\n\n\nAT\n25.5 °C\n\n\nV\n51.1 cm-hg\n\n\nAP\n995.6 milibar\n\n\nRH\n52.2 %\n\n\n\n\n\nCode\n# Definimos un nuevo caso de prueba con los siguientes valores\nnuevo_caso = pd.DataFrame({\n    'AT': [25.5],     # Temperatura\n    'V': [51.1],       # Exhaust Vacuum\n    'AP': [995.6],      # Ambient Pressure\n    'RH': [52.2],     # Relative Humidity\n    })\n\n# Realizamos la predicción con el nuevo caso de prueba\nprediccion = pipe.predict(nuevo_caso)\n\n# Imprimimos el resultado de la predicción\nprint(f'La potencia entregada [MW] estimada es: {prediccion[0]:.2f} MW')\n\n\nLa potencia entregada [MW] estimada es: 445.86 MW\n\n\n\n\n\n\n\nCode\n# Calcular métricas de evaluación\nr2_test = r2_score(y_test, y_pred_test)\nmse_test = mean_squared_error(y_test, y_pred_test)\nrmse_test = mse_test ** 0.5 \n\n# ----------------------------------------------------------------------\n# Mostrar Resultados\n# ----------------------------------------------------------------------\n\nprint('EVALUACIÓN FINAL DEL MODELO EN CONJUNTO DE PRUEBA (X_test)')\nprint(f'Modelo: Regresión Lineal (entrenado con {X_train.shape}')\nprint(f'Número de muestras en el conjunto de Prueba: {X_test.shape}')\n\nprint(f'* R² Score (Coeficiente de Determinación): {r2_test:.4f}')\nprint(f'* Error Cuadrático Medio (MSE): {mse_test:.3f}')\nprint(f'* Raíz del Error Cuadrático Medio (RMSE): {rmse_test:.3f}')\n\n\nEVALUACIÓN FINAL DEL MODELO EN CONJUNTO DE PRUEBA (X_test)\nModelo: Regresión Lineal (entrenado con (6697, 4)\nNúmero de muestras en el conjunto de Prueba: (2871, 4)\n* R² Score (Coeficiente de Determinación): 0.9275\n* Error Cuadrático Medio (MSE): 21.240\n* Raíz del Error Cuadrático Medio (RMSE): 4.609\n\n\n\n\n\n\n\nCode\n# Graficamos los valores reales vs los valores predichos\nplt.figure(figsize=(10, 6))\nplt.scatter(y_test, y_pred_test, color='blue', alpha=0.7, s=10)\nplt.title('Potencia real vs. Potencia predicha')\nplt.xlabel('Valores reales')\nplt.ylabel('Valores predichos')\nplt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Línea de referencia\nplt.legend(['Valores predichos', 'Línea de referencia'])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import mean_squared_error\n\n\ntrain_sizes, train_scores, test_scores = learning_curve(\n    estimator=pipe, \n    X=X_train,         \n    y=y_train,\n    train_sizes=np.linspace(0.1, 1.0, 10),  # 10 puntos de muestra de tamaño de datos\n    cv=5,                                   # 5-Fold Cross-Validation interna\n    scoring='neg_mean_squared_error',\n    n_jobs=1,\n    random_state=42\n)\n\n\ntrain_mse = -train_scores.mean(axis=1)\ntest_mse = -test_scores.mean(axis=1)\n\n\nplt.figure(figsize=(10, 6))\n\nplt.plot(train_sizes, train_mse, 'o-', color='blue', label='Error de Entrenamiento (MSE)')\nplt.plot(train_sizes, test_mse, 'o-', color='green', label='Error de Validación Cruzada (MSE)')\n\n\nplt.title('Curva de Aprendizaje para Regresión Lineal', fontsize=14)\nplt.xlabel('Tamaño del Conjunto de Entrenamiento', fontsize=12)\nplt.ylabel('Error Cuadrático Medio (MSE)', fontsize=12)\nplt.ylim(0, max(max(train_mse), max(test_mse)) * 1.1) \nplt.legend(loc='best')\nplt.grid(True, linestyle=':', alpha=0.7)\n\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nLas métricas del modelo es definen al modelo con una alta precisión:\n\nR² Score de 0.9275 es alto donde la varianza de la variable objetivo (PE) se explica muy bien por parte las varibales predictoras (AT, V, AP, RH). Esto se confirma por la matriz de correlación.\nError Cuadrático Medio (MSE) de 21.240 MW² mide el promedio de errores al cuadrado. Para contextualizar mejor este dato se observara Raíz del Error Cuadrático Medio (RMSE).\nRaíz del Error Cuadrático Medio (RMSE) de 4.609 MW es error promedio. Esto significa que los valores predichos se desvian un 4.609 MW de la linea de referencia. Como se muestra en la gráfica Potencia Real vs. Potencia predicha los valores predichos (puntos azules) se agrlomeran cerca de la linea de referencia (linea entrecortada roja). Mientras mas cerca se agrupen los valores predichos a las linea de referencia el RMSE se acercaria a cero.\n\n\n\n\nimage.png\n\n\nCOn un R² Score de 0.9275 se observa en la figura de la curva de aprendizaje, la curva Error de Entrenamiento (MSE) aumenta a medida que se entrena el modelo con mayor cantidad de muestras. A partir de 1700 muestras el valor se incrementa y comienza a estabilizarce con el calculo del Error de Validación Cruzada. Ambas lineas a partir de 2700 comienzan a converger y a sobreponerse. Esto es de esperarse con el valor de R² Score de 0.9275 y se mantiene hasta el final de l entraamiento cuando llega a definirse el modelo con las 6697 observaciones.\n\n\n\nimage.png"
  },
  {
    "objectID": "index.html#carga-y-exploración-inicial-del-dataset",
    "href": "index.html#carga-y-exploración-inicial-del-dataset",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Se realiza un descripción de las variables y de la variable objetivo (Target)\n\n\n\n\n\n\n\n\n\n\nVariable Name\nRole\nType\nDescription\nUnits\n\n\n\n\nAT\nFeature\nContinuous\nen el rango 1.81°C and 37.11°C\nC\n\n\nV\nFeature\nContinuous\nen el rango 25.36-81.56 cm Hg\ncm Hg\n\n\nAP\nFeature\nContinuous\nen el rango 992.89-1033.30 milibar\nmilibar\n\n\nRH\nFeature\nContinuous\nen el rango 25.56% a 100.16%\n%\n\n\nPE\nTarget\nContinuous\n420.26-495.76 MW\nMW\n\n\n\n\n\nCode\n# Importamos los paquetes necesarios\nfrom sklearn.linear_model import LinearRegression # Regresión lineal con scikit-learn\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\n\nimport altair as alt\nimport pandas as pd\n\nMW_df = pd.read_csv(r'data\\Ciclo_conbinado.csv', delimiter=';', encoding='latin-1')\n\nMW_df.head()\n\n\n\n\n\n\n\n\n\nAT\nV\nAP\nRH\nPE\n\n\n\n\n0\n14.96\n41.76\n1024.07\n73.17\n463.26\n\n\n1\n25.18\n62.96\n1020.04\n59.08\n444.37\n\n\n2\n5.11\n39.40\n1012.16\n92.14\n488.56\n\n\n3\n20.86\n57.32\n1010.24\n76.64\n446.48\n\n\n4\n10.82\n37.50\n1009.23\n96.62\n473.90\n\n\n\n\n\n\n\nPrincipales estadisticas:\n\n\nCode\nMW_df.describe()\n\n\n\n\n\n\n\n\n\nAT\nV\nAP\nRH\nPE\n\n\n\n\ncount\n9568.000000\n9568.000000\n9568.000000\n9568.000000\n9568.000000\n\n\nmean\n19.651231\n54.305804\n1013.259078\n73.308978\n454.365009\n\n\nstd\n7.452473\n12.707893\n5.938784\n14.600269\n17.066995\n\n\nmin\n1.810000\n25.360000\n992.890000\n25.560000\n420.260000\n\n\n25%\n13.510000\n41.740000\n1009.100000\n63.327500\n439.750000\n\n\n50%\n20.345000\n52.080000\n1012.940000\n74.975000\n451.550000\n\n\n75%\n25.720000\n66.540000\n1017.260000\n84.830000\n468.430000\n\n\nmax\n37.110000\n81.560000\n1033.300000\n100.160000\n495.760000\n\n\n\n\n\n\n\nMatriz de correlación entre las diferentes variables\n\n\nCode\nmatriz_correlacion = MW_df.corr(method='pearson')\n\nplt.figure(figsize=(10, 8))\n\nsns.heatmap(\n    matriz_correlacion,\n    annot=True,          # Muestra el valor de correlación en cada celda\n    fmt='.2f',           # Dos decimales\n    cmap='coolwarm',     # Esquema de color divergente (rojo para positivo, azul para negativo)\n    linewidths=.5,       \n    cbar_kws={'label': 'Coeficiente de Correlación'} \n)\n\nplt.title('Matriz de Correlación de Combined Cycle Power Plant', fontsize=16)\nplt.show()\n\n\n\n\n\n\n\n\n\nVariables con una alta correlación positiva. Es decir, mientras una variable aumenta la otra variable aumenta:\n\nV vs AT (0.84)\n\nVariables con una alta correlación negativa. Es decir, mientras una variable aumenta la otra variable disminuye:\n\nRH vs AT (-0.54)\nAP vs AT (-0.51)\n\nVariables con una alta correlación con la variable objetivo PE (MW):\n\nPE vs AT (-0.95) negativa\nPE vs V (-0.87) negativa\nAP vs PE (0.52) positiva\n\n\n\nCode\nalt.data_transformers.disable_max_rows()\n\nnumerical_columns = MW_df.select_dtypes('number').columns.tolist()\n\nalt.Chart(MW_df).mark_rect().encode(\n    alt.X(alt.repeat('column'),type='quantitative',bin=alt.Bin(maxbins=30)),\n    alt.Y(alt.repeat('row'),type='quantitative',bin=alt.Bin(maxbins=30)),\n    alt.Color('count()'),\n    alt.Tooltip('count()')\n).properties(\n    width=100,\n    height=100\n).repeat(\n    column=numerical_columns,\n    row=numerical_columns\n).resolve_scale(\n    color='independent'\n)\n\n\n\n\n\n\n\n\nSe observa con mayor claridad en el Heatmap Matrix las relaciones presentadas en la matriz de correlación.\nEspecialmente, PE vs AT (-0.95), V vs AT (0.84) y PE vs V (-0.87).\n\n\nCode\nheatmap_scatter = alt.Chart(MW_df).mark_rect().encode(\n    alt.X('AT', bin=alt.Bin(maxbins=100)),\n    alt.Y('PE', bin=alt.Bin(maxbins=100)),\n    alt.Color('count()'),\n    alt.Tooltip('count()')\n).properties(\n    title=\"Binned Heatmap: AT vs PE\"\n)\n\nheatmap_scatter"
  },
  {
    "objectID": "index.html#división-en-conjuntos-de-entrenamiento-y-prueba-train_test_split",
    "href": "index.html#división-en-conjuntos-de-entrenamiento-y-prueba-train_test_split",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Code\nfor col in MW_df.columns:\n    MW_df[col] = pd.to_numeric(MW_df[col], errors='coerce')\nMW_df = MW_df.dropna()\n\n\n\n\nCode\nfrom sklearn.model_selection import train_test_split\n\nX = MW_df.drop('PE', axis=1) # Predictoras\ny = MW_df['PE']  \n\n\n# Dividimos directamente, usando el 70% para entrenamiento y 30% para prueba.\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, \n    test_size=0.3, # 30% para prueba\n    random_state=42\n)\n\nprint(f'Dimensiones de X_train (Entrenamiento): {X_train.shape}')\nprint(f'Dimensiones de X_test (Prueba): {X_test.shape}\\n')\n\n\nDimensiones de X_train (Entrenamiento): (6697, 4)\nDimensiones de X_test (Prueba): (2871, 4)"
  },
  {
    "objectID": "index.html#definición-y-entrenamiento-del-modelo-utilizando-pipeline",
    "href": "index.html#definición-y-entrenamiento-del-modelo-utilizando-pipeline",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Code\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Pipeline: Estandarización de los datos y Regresión Lineal\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('regressor', LinearRegression())\n])\n\n# Entrenamiento del modelo con el conjunto de ENTRENAMIENTO\npipe.fit(X_train, y_train)\n\n# Evaluación en el Conjunto de PRUEBA (X_test)\ny_pred_test = pipe.predict(X_test)"
  },
  {
    "objectID": "index.html#generación-de-predicciones",
    "href": "index.html#generación-de-predicciones",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Se realizara una nueva predicción con nuevos datos nunca vistos:\n\n\n\nVariable\nValor\n\n\n\n\nAT\n25.5 °C\n\n\nV\n51.1 cm-hg\n\n\nAP\n995.6 milibar\n\n\nRH\n52.2 %\n\n\n\n\n\nCode\n# Definimos un nuevo caso de prueba con los siguientes valores\nnuevo_caso = pd.DataFrame({\n    'AT': [25.5],     # Temperatura\n    'V': [51.1],       # Exhaust Vacuum\n    'AP': [995.6],      # Ambient Pressure\n    'RH': [52.2],     # Relative Humidity\n    })\n\n# Realizamos la predicción con el nuevo caso de prueba\nprediccion = pipe.predict(nuevo_caso)\n\n# Imprimimos el resultado de la predicción\nprint(f'La potencia entregada [MW] estimada es: {prediccion[0]:.2f} MW')\n\n\nLa potencia entregada [MW] estimada es: 445.86 MW"
  },
  {
    "objectID": "index.html#evaluación-del-modelo-con-métricas-apropiadas",
    "href": "index.html#evaluación-del-modelo-con-métricas-apropiadas",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Code\n# Calcular métricas de evaluación\nr2_test = r2_score(y_test, y_pred_test)\nmse_test = mean_squared_error(y_test, y_pred_test)\nrmse_test = mse_test ** 0.5 \n\n# ----------------------------------------------------------------------\n# Mostrar Resultados\n# ----------------------------------------------------------------------\n\nprint('EVALUACIÓN FINAL DEL MODELO EN CONJUNTO DE PRUEBA (X_test)')\nprint(f'Modelo: Regresión Lineal (entrenado con {X_train.shape}')\nprint(f'Número de muestras en el conjunto de Prueba: {X_test.shape}')\n\nprint(f'* R² Score (Coeficiente de Determinación): {r2_test:.4f}')\nprint(f'* Error Cuadrático Medio (MSE): {mse_test:.3f}')\nprint(f'* Raíz del Error Cuadrático Medio (RMSE): {rmse_test:.3f}')\n\n\nEVALUACIÓN FINAL DEL MODELO EN CONJUNTO DE PRUEBA (X_test)\nModelo: Regresión Lineal (entrenado con (6697, 4)\nNúmero de muestras en el conjunto de Prueba: (2871, 4)\n* R² Score (Coeficiente de Determinación): 0.9275\n* Error Cuadrático Medio (MSE): 21.240\n* Raíz del Error Cuadrático Medio (RMSE): 4.609"
  },
  {
    "objectID": "index.html#visualizaciones-e-interpretación-de-resultados",
    "href": "index.html#visualizaciones-e-interpretación-de-resultados",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Code\n# Graficamos los valores reales vs los valores predichos\nplt.figure(figsize=(10, 6))\nplt.scatter(y_test, y_pred_test, color='blue', alpha=0.7, s=10)\nplt.title('Potencia real vs. Potencia predicha')\nplt.xlabel('Valores reales')\nplt.ylabel('Valores predichos')\nplt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')  # Línea de referencia\nplt.legend(['Valores predichos', 'Línea de referencia'])\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import mean_squared_error\n\n\ntrain_sizes, train_scores, test_scores = learning_curve(\n    estimator=pipe, \n    X=X_train,         \n    y=y_train,\n    train_sizes=np.linspace(0.1, 1.0, 10),  # 10 puntos de muestra de tamaño de datos\n    cv=5,                                   # 5-Fold Cross-Validation interna\n    scoring='neg_mean_squared_error',\n    n_jobs=1,\n    random_state=42\n)\n\n\ntrain_mse = -train_scores.mean(axis=1)\ntest_mse = -test_scores.mean(axis=1)\n\n\nplt.figure(figsize=(10, 6))\n\nplt.plot(train_sizes, train_mse, 'o-', color='blue', label='Error de Entrenamiento (MSE)')\nplt.plot(train_sizes, test_mse, 'o-', color='green', label='Error de Validación Cruzada (MSE)')\n\n\nplt.title('Curva de Aprendizaje para Regresión Lineal', fontsize=14)\nplt.xlabel('Tamaño del Conjunto de Entrenamiento', fontsize=12)\nplt.ylabel('Error Cuadrático Medio (MSE)', fontsize=12)\nplt.ylim(0, max(max(train_mse), max(test_mse)) * 1.1) \nplt.legend(loc='best')\nplt.grid(True, linestyle=':', alpha=0.7)\n\nplt.show()"
  },
  {
    "objectID": "index.html#resultados-obtenidos",
    "href": "index.html#resultados-obtenidos",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Las métricas del modelo es definen al modelo con una alta precisión:\n\nR² Score de 0.9275 es alto donde la varianza de la variable objetivo (PE) se explica muy bien por parte las varibales predictoras (AT, V, AP, RH). Esto se confirma por la matriz de correlación.\nError Cuadrático Medio (MSE) de 21.240 MW² mide el promedio de errores al cuadrado. Para contextualizar mejor este dato se observara Raíz del Error Cuadrático Medio (RMSE).\nRaíz del Error Cuadrático Medio (RMSE) de 4.609 MW es error promedio. Esto significa que los valores predichos se desvian un 4.609 MW de la linea de referencia. Como se muestra en la gráfica Potencia Real vs. Potencia predicha los valores predichos (puntos azules) se agrlomeran cerca de la linea de referencia (linea entrecortada roja). Mientras mas cerca se agrupen los valores predichos a las linea de referencia el RMSE se acercaria a cero.\n\n\n\n\nimage.png\n\n\nCOn un R² Score de 0.9275 se observa en la figura de la curva de aprendizaje, la curva Error de Entrenamiento (MSE) aumenta a medida que se entrena el modelo con mayor cantidad de muestras. A partir de 1700 muestras el valor se incrementa y comienza a estabilizarce con el calculo del Error de Validación Cruzada. Ambas lineas a partir de 2700 comienzan a converger y a sobreponerse. Esto es de esperarse con el valor de R² Score de 0.9275 y se mantiene hasta el final de l entraamiento cuando llega a definirse el modelo con las 6697 observaciones.\n\n\n\nimage.png"
  },
  {
    "objectID": "Regresion_Logistica.html",
    "href": "Regresion_Logistica.html",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "INEC_NACIDOSVIVOS_2024.csv\nInstituto Nacional de Estadística y Censos\nBase de datos del Registro Estadístico de Nacido Vivo 2024\nhttps://datosabiertos.gob.ec/dataset/registro-estadistico-de-nacido-vivo-2024/resource/df82df80-029d-49b1-9825-cd03121939e3\n\n\n\nimage.png\n\n\nEl conjunto de datos contiene 217986 observaciones del año 2024. Al no existir una variable declarada de antemano como target. Se opto utilizar como variable objetivo “tipo_parto”. Cuya varible posee dos opciones: “Normal” o “Cesarea”.\nSe realizara una exploración de las variables y definir como estas se relacionan con el target seleccionado.\n\n\nSe realiza un descripción de las variables y de la variable objetivo (Target)\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport altair as alt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score\n\nnacidos_df = pd.read_csv(r'data\\inec_nacidos_vivos_2024.csv', delimiter=';', encoding='latin-1')\n\nalt.data_transformers.disable_max_rows()\n\nnacidos_df.head()\n\n\n\n\n\n\n\n\n\nsexo\nanio_nacimiento\nmes_nacimiento\ndia_nacimiento\nfecha_nacimiento\ntalla\npeso\nsem_gestacion\ntipo_parto\nlugar_ocurrido\narea_nacimiento\netnia\nestado_civil\nnivel_instruccion\n\n\n\n\n0\nMujer\n2023\nOctubre\n2\n10/2/2023\n49\n3050\n38\nNormal\nHospital, Clínica o Consultorio Privado\nRural\nIndígena\nCasada\nPrimaria\n\n\n1\nMujer\n2024\nJulio\n31\n7/31/2024\n52\n3230\n40\nNormal\nHospital, Clínica o Consultorio Privado\nRural\nIndígena\nCasada\nEducación Básica\n\n\n2\nHombre\n2024\nAbril\n28\n4/28/2024\n47\n2360\n34\nNormal\nHospital, Clínica o Consultorio Privado\nRural\nMestiza\nSoltera\nPrimaria\n\n\n3\nHombre\n2024\nAgosto\n10\n8/10/2024\n50\n3360\n40\nNormal\nHospital, Clínica o Consultorio Privado\nRural\nIndígena\nCasada\nEducación Básica\n\n\n4\nHombre\n2024\nEnero\n1\n1/1/2024\n51\n2770\n40\nNormal\nHospital, Clínica o Consultorio Privado\nRural\nIndígena\nCasada\nPrimaria\n\n\n\n\n\n\n\n\n\nSe revisa si existe sesgo en la variable target. Las variables predictoras oscilan muy cerca del 50% por lo que se concluye que no existe sesgo en el dataset.\n\n\nCode\nconteo_clases = nacidos_df['tipo_parto'].value_counts()/nacidos_df.shape[0]\nprint(\"\\nConteo de Frecuencia por Clase:\")\nprint(conteo_clases)\n\n\n\nConteo de Frecuencia por Clase:\ntipo_parto\nCesárea    0.509946\nNormal     0.490054\nName: count, dtype: float64\n\n\nSe visualiza las cantidad de datos nulos en el dataset.\n\n\nCode\n# Contar la cantidad de valores nulos por columna\nprint(\"--- Cantidad de valores nulos por columna ---\")\nvalores_nulos = nacidos_df.isnull().sum()\nprint(valores_nulos)\n\n# Contar la cantidad de valores con el texto 'Sin información' (que parece ser un valor nulo en este dataset)\nprint(\"\\n--- Cantidad de valores 'Sin información' por columna ---\")\nsin_informacion = (nacidos_df == 'Sin información').sum()\nprint(sin_informacion)\n\n\n--- Cantidad de valores nulos por columna ---\nsexo                 0\nanio_nacimiento      0\nmes_nacimiento       0\ndia_nacimiento       0\nfecha_nacimiento     0\ntalla                0\npeso                 0\nsem_gestacion        0\ntipo_parto           0\nlugar_ocurrido       0\narea_nacimiento      0\netnia                0\nestado_civil         0\nnivel_instruccion    0\ndtype: int64\n\n--- Cantidad de valores 'Sin información' por columna ---\nsexo                    0\nanio_nacimiento         0\nmes_nacimiento          0\ndia_nacimiento          0\nfecha_nacimiento        0\ntalla                6663\npeso                 6613\nsem_gestacion        6848\ntipo_parto              0\nlugar_ocurrido          0\narea_nacimiento         0\netnia                5611\nestado_civil         2352\nnivel_instruccion    2245\ndtype: int64\n\n\nLa graficas muestran que las variables no poseen una correlación uniforme. Es decir, no existe una correlación importante que explique el comportamiento de la variable objetivo (‘tipo_parto’)\n\n\nCode\nnumerical_columns = nacidos_df.select_dtypes('number').columns.tolist()\n\nalt.Chart(nacidos_df).mark_rect().encode(\n    alt.X(alt.repeat('column'),type='quantitative',bin=alt.Bin(maxbins=30)),\n    alt.Y(alt.repeat('row'),type='quantitative',bin=alt.Bin(maxbins=30)),\n    alt.Color('count()'),\n    alt.Tooltip('count()')\n).properties(\n    width=100,\n    height=100\n).repeat(\n    column=numerical_columns,\n    row=numerical_columns\n).resolve_scale(\n    color='independent'\n)\n\n\n\n\n\n\n\n\n\n\n\n\nAntes de realizar cualquier transformación en el dataset vamos a separar el grupo de entrenamiento y prueba:\n\n\nCode\n# Tratamos los valores 'tipo_parto'\nle = LabelEncoder()\nnacidos_df['tipo_parto_cod'] = le.fit_transform(nacidos_df['tipo_parto'].astype(str))\n\nprint(\"Mapeo de Codificación (Valor original : Valor numérico):\")\nmapeo_parto = dict(zip(le.classes_, le.transform(le.classes_)))\nprint(f\"*'tipo_parto_cod'--{mapeo_parto}\")\n\n\nMapeo de Codificación (Valor original : Valor numérico):\n*'tipo_parto_cod'--{'Cesárea': np.int64(0), 'Normal': np.int64(1)}\n\n\n\n\nCode\n# Definición de X e y\ny = nacidos_df['tipo_parto_cod']\nX = nacidos_df.drop(columns=['tipo_parto_cod', 'tipo_parto', 'fecha_nacimiento'])\n\n\nPreparamos dos pipelines para tratar los valores faltantes en las variables numericas y categoricas:\n\ncaracteristicas_mumericas = [‘talla’, ‘peso’, ‘sem_gestacion’, ‘anio_nacimiento’, ‘dia_nacimiento’]\ncaracteristicas_categoricas = [‘sexo’, ‘mes_nacimiento’, ‘lugar_ocurrido’, ‘area_nacimiento’, ‘etnia’, ‘estado_civil’, ‘nivel_instruccion’]\n\n\n\n\n\n\nCode\n# Definición de tipos de columnas numericas y categiricas\ncaracteristicas_mumericas = ['talla', 'peso', 'sem_gestacion', 'anio_nacimiento', 'dia_nacimiento']\ncaracteristicas_categoricas = ['sexo', 'mes_nacimiento', 'lugar_ocurrido', 'area_nacimiento', 'etnia', 'estado_civil', 'nivel_instruccion']\n\n# Pipeline para Datos Numericos\ntransform_numerica = Pipeline(steps=[\n    # Reemplazar la cadena 'Sin información' por NaN para imputación numérica\n    ('str_imputer', SimpleImputer(missing_values='Sin información', strategy='constant', fill_value=np.nan)),\n    # Imputar NaN con la mediana\n    ('num_imputer', SimpleImputer(strategy='median')),\n    # Escalar\n    ('scaler', StandardScaler())\n])\n\n# Pipeline para Datos Categoricos\ntransform_categorica = Pipeline(steps=[\n    # Reemplazar 'Sin información' con 'Desconocido'\n    ('str_imputer', SimpleImputer(missing_values='Sin información', strategy='constant', fill_value='Desconocido')),\n    # Imputar cualquier otro nulo con la moda\n    ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n    # Codificar con One-Hot Encoding\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n# ColumnTransformer combinamos todos los pipelines\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', transform_numerica, caracteristicas_mumericas),\n        ('cat', transform_categorica, caracteristicas_categoricas)\n    ],\n    remainder='drop'    # Eliminamos todas las columnas que no van a ser tratadas por pipeline\n)\n\n\nUso de train_test_split para separar el dataset en entrenamiento y prueba:\n\n\nCode\n# --- División de Datos ---\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Pipeline Final (ColumnTransform + Modelo)\nlog_reg_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', LogisticRegression(random_state=42, max_iter=2000))\n])\n\n# Entrenamiento\nlog_reg_pipeline.fit(X_train, y_train)\n\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('str_imputer',\n                                                                   SimpleImputer(fill_value=nan,\n                                                                                 missing_values='Sin '\n                                                                                                'información',\n                                                                                 strategy='constant')),\n                                                                  ('num_imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['talla', 'peso',\n                                                   'sem_gestacion',\n                                                   'anio_nacimiento',\n                                                   'dia_nacimiento']),\n                                                 ('cat',\n                                                  Pipeline...\n                                                                                 missing_values='Sin '\n                                                                                                'información',\n                                                                                 strategy='constant')),\n                                                                  ('cat_imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(handle_unknown='ignore',\n                                                                                 sparse_output=False))]),\n                                                  ['sexo', 'mes_nacimiento',\n                                                   'lugar_ocurrido',\n                                                   'area_nacimiento', 'etnia',\n                                                   'estado_civil',\n                                                   'nivel_instruccion'])])),\n                ('classifier',\n                 LogisticRegression(max_iter=2000, random_state=42))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Pipeline?Documentation for PipelineiFitted\n        \n            \n                Parameters\n                \n\n\n\n\nsteps \n[('preprocessor', ...), ('classifier', ...)]\n\n\n\ntransform_input \nNone\n\n\n\nmemory \nNone\n\n\n\nverbose \nFalse\n\n\n\n\n            \n        \n    preprocessor: ColumnTransformer?Documentation for preprocessor: ColumnTransformer\n        \n            \n                Parameters\n                \n\n\n\n\ntransformers \n[('num', ...), ('cat', ...)]\n\n\n\nremainder \n'drop'\n\n\n\nsparse_threshold \n0.3\n\n\n\nn_jobs \nNone\n\n\n\ntransformer_weights \nNone\n\n\n\nverbose \nFalse\n\n\n\nverbose_feature_names_out \nTrue\n\n\n\nforce_int_remainder_cols \n'deprecated'\n\n\n\n\n            \n        \n    num['talla', 'peso', 'sem_gestacion', 'anio_nacimiento', 'dia_nacimiento']SimpleImputer?Documentation for SimpleImputer\n        \n            \n                Parameters\n                \n\n\n\n\nmissing_values \n'Sin información'\n\n\n\nstrategy \n'constant'\n\n\n\nfill_value \nnan\n\n\n\ncopy \nTrue\n\n\n\nadd_indicator \nFalse\n\n\n\nkeep_empty_features \nFalse\n\n\n\n\n            \n        \n    SimpleImputer?Documentation for SimpleImputer\n        \n            \n                Parameters\n                \n\n\n\n\nmissing_values \nnan\n\n\n\nstrategy \n'median'\n\n\n\nfill_value \nNone\n\n\n\ncopy \nTrue\n\n\n\nadd_indicator \nFalse\n\n\n\nkeep_empty_features \nFalse\n\n\n\n\n            \n        \n    StandardScaler?Documentation for StandardScaler\n        \n            \n                Parameters\n                \n\n\n\n\ncopy \nTrue\n\n\n\nwith_mean \nTrue\n\n\n\nwith_std \nTrue\n\n\n\n\n            \n        \n    cat['sexo', 'mes_nacimiento', 'lugar_ocurrido', 'area_nacimiento', 'etnia', 'estado_civil', 'nivel_instruccion']SimpleImputer?Documentation for SimpleImputer\n        \n            \n                Parameters\n                \n\n\n\n\nmissing_values \n'Sin información'\n\n\n\nstrategy \n'constant'\n\n\n\nfill_value \n'Desconocido'\n\n\n\ncopy \nTrue\n\n\n\nadd_indicator \nFalse\n\n\n\nkeep_empty_features \nFalse\n\n\n\n\n            \n        \n    SimpleImputer?Documentation for SimpleImputer\n        \n            \n                Parameters\n                \n\n\n\n\nmissing_values \nnan\n\n\n\nstrategy \n'most_frequent'\n\n\n\nfill_value \nNone\n\n\n\ncopy \nTrue\n\n\n\nadd_indicator \nFalse\n\n\n\nkeep_empty_features \nFalse\n\n\n\n\n            \n        \n    OneHotEncoder?Documentation for OneHotEncoder\n        \n            \n                Parameters\n                \n\n\n\n\ncategories \n'auto'\n\n\n\ndrop \nNone\n\n\n\nsparse_output \nFalse\n\n\n\ndtype \n&lt;class 'numpy.float64'&gt;\n\n\n\nhandle_unknown \n'ignore'\n\n\n\nmin_frequency \nNone\n\n\n\nmax_categories \nNone\n\n\n\nfeature_name_combiner \n'concat'\n\n\n\n\n            \n        \n    LogisticRegression?Documentation for LogisticRegression\n        \n            \n                Parameters\n                \n\n\n\n\npenalty \n'l2'\n\n\n\ndual \nFalse\n\n\n\ntol \n0.0001\n\n\n\nC \n1.0\n\n\n\nfit_intercept \nTrue\n\n\n\nintercept_scaling \n1\n\n\n\nclass_weight \nNone\n\n\n\nrandom_state \n42\n\n\n\nsolver \n'lbfgs'\n\n\n\nmax_iter \n2000\n\n\n\nmulti_class \n'deprecated'\n\n\n\nverbose \n0\n\n\n\nwarm_start \nFalse\n\n\n\nn_jobs \nNone\n\n\n\nl1_ratio \nNone\n\n\n\n\n            \n        \n    \n\n\n\n\n\n\n\nCode\n# Predicción\ny_pred = log_reg_pipeline.predict(X_test)\n\n\n\n\n\n\n\nCode\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\"Precisión (Accuracy) en el conjunto de prueba: {accuracy:.4f}\")\n\nprint(\"Reporte de Clasificación:\")\nprint(classification_report(y_test, y_pred))\n\n\nPrecisión (Accuracy) en el conjunto de prueba: 0.7312\nReporte de Clasificación:\n              precision    recall  f1-score   support\n\n           0       0.81      0.62      0.70     22233\n           1       0.68      0.85      0.76     21365\n\n    accuracy                           0.73     43598\n   macro avg       0.74      0.73      0.73     43598\nweighted avg       0.75      0.73      0.73     43598\n\n\n\n\n\n\nMatriz de confución:\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred)\n\n# 'le' fue el LabelEncoder que codificó 'tipo_parto'\nclases = le.classes_ \n\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,          # Mostrar los valores numéricos en las celdas\n    fmt='d',             # Formato decimal (para números enteros)\n    cmap='Blues',        # Escala de color\n    xticklabels=clases,  # Etiquetas del eje X (Predichas)\n    yticklabels=clases,  # Etiquetas del eje Y (Reales)\n    cbar=False           \n)\nplt.title('Matriz de Confusión del Modelo de Regresión Logística', fontsize=14)\nplt.ylabel('Valores Reales (True Label)', fontsize=12)\nplt.xlabel('Valores Predichos (Predicted Label)', fontsize=12)\nplt.show()\n\n\n\n\n\n\n\n\n\nCurva ROC.\n\n\nCode\nfrom sklearn.metrics import roc_curve, auc\n\n# 1. Obtener las probabilidades de la clase positiva (Clase 1)\n# El método predict_proba devuelve las probabilidades para todas las clases.\n# Seleccionamos el índice [:, 1] que corresponde a la probabilidad de la clase positiva (1).\ny_probs = log_reg_pipeline.predict_proba(X_test)[:, 1]\n\n# 2. Calcular la Curva ROC\n# roc_curve devuelve: FPR (Tasa de Falsos Positivos), TPR (Tasa de Verdaderos Positivos), y Umbrales\nfpr, tpr, thresholds = roc_curve(y_test, y_probs)\n\n# 3. Calcular el Área Bajo la Curva (AUC)\n# El AUC es una métrica de resumen del rendimiento del clasificador.\nroc_auc = auc(fpr, tpr)\n\nprint(f\"Área Bajo la Curva (AUC): {roc_auc:.4f}\")\n\n\nÁrea Bajo la Curva (AUC): 0.7986\n\n\n\n\nCode\n# 4. Graficar la Curva ROC\nplt.figure(figsize=(8, 6))\n\n# Trazar la curva ROC principal\nplt.plot(\n    fpr, tpr, \n    color='darkorange', \n    lw=2, \n    label=f'Curva ROC (área = {roc_auc:.4f})'\n)\n\n# Trazar la línea de referencia (Clasificador Aleatorio)\nplt.plot(\n    [0, 1], [0, 1], \n    color='navy', \n    lw=2, \n    linestyle='--', \n    label='Clasificador Aleatorio (área = 0.50)'\n)\n\n# Configuración del gráfico\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Tasa de Falsos Positivos (FPR)', fontsize=12)\nplt.ylabel('Tasa de Verdaderos Positivos (TPR)', fontsize=12)\nplt.title('Curva ROC para Regresión Logística', fontsize=14)\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nLas métricas del ML definen al modelo como moderada:\n\nAccuracy de 0.7312 es moderado. Es decir, de cada 100 nacimientos, el modelo predijo correctamente el tipo de parto de 73 de ellos.\nPrecision de 0.74 mide el promedio de errores al cuadrado. Para contextualizar mejor este dato se observara Raíz del Error Cuadrático Medio (RMSE).\nRecall de 0.73 significa que e todos los nacimientos que realmente pertenecían a la Clase Positiva (Cesárea), el modelo logró identificar correctamente el 73%.\nF1 Score de 0.73 indica que el modelo ha logrado un equilibrio sólido entre el Recall y Precision.\nMatriz de confusión determina que existen 3272 Verdaderos negativo y 8446 falsos negativos. En el contexto de este dataset y el objetivo de predecir si las variables describen la varianza de la variable objetibo (Tipo de parto: Norma o Cesárea) existe un gran numero de predicciones erroneas.\n\n\n\n\nimage.png\n\n\n\nCurva ROC de 0.7986 significa que sí tomas¿mos al azar un nacimiento que resultó en la clase cesárea y un nacimiento que resultó normal, el modelo tiene una probabilidad del 79.86% de asignar una probabilidad más alta al nacimiento que realmente pertenece a cesárea.\n\n\n\n\nimage.png\n\n\nLa explicación de que la mayoria de metricas esten cerca del 0.73 se explica por el balance de la variable objetivo\ntipo_parto\n\nCesárea 50.9946 %\nNormal 49.0054 %"
  },
  {
    "objectID": "Regresion_Logistica.html#carga-y-exploración-inicial-del-dataset",
    "href": "Regresion_Logistica.html#carga-y-exploración-inicial-del-dataset",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Se realiza un descripción de las variables y de la variable objetivo (Target)\n\n\nCode\nimport pandas as pd\nimport numpy as np\nimport altair as alt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score\n\nnacidos_df = pd.read_csv(r'data\\inec_nacidos_vivos_2024.csv', delimiter=';', encoding='latin-1')\n\nalt.data_transformers.disable_max_rows()\n\nnacidos_df.head()\n\n\n\n\n\n\n\n\n\nsexo\nanio_nacimiento\nmes_nacimiento\ndia_nacimiento\nfecha_nacimiento\ntalla\npeso\nsem_gestacion\ntipo_parto\nlugar_ocurrido\narea_nacimiento\netnia\nestado_civil\nnivel_instruccion\n\n\n\n\n0\nMujer\n2023\nOctubre\n2\n10/2/2023\n49\n3050\n38\nNormal\nHospital, Clínica o Consultorio Privado\nRural\nIndígena\nCasada\nPrimaria\n\n\n1\nMujer\n2024\nJulio\n31\n7/31/2024\n52\n3230\n40\nNormal\nHospital, Clínica o Consultorio Privado\nRural\nIndígena\nCasada\nEducación Básica\n\n\n2\nHombre\n2024\nAbril\n28\n4/28/2024\n47\n2360\n34\nNormal\nHospital, Clínica o Consultorio Privado\nRural\nMestiza\nSoltera\nPrimaria\n\n\n3\nHombre\n2024\nAgosto\n10\n8/10/2024\n50\n3360\n40\nNormal\nHospital, Clínica o Consultorio Privado\nRural\nIndígena\nCasada\nEducación Básica\n\n\n4\nHombre\n2024\nEnero\n1\n1/1/2024\n51\n2770\n40\nNormal\nHospital, Clínica o Consultorio Privado\nRural\nIndígena\nCasada\nPrimaria\n\n\n\n\n\n\n\n\n\nSe revisa si existe sesgo en la variable target. Las variables predictoras oscilan muy cerca del 50% por lo que se concluye que no existe sesgo en el dataset.\n\n\nCode\nconteo_clases = nacidos_df['tipo_parto'].value_counts()/nacidos_df.shape[0]\nprint(\"\\nConteo de Frecuencia por Clase:\")\nprint(conteo_clases)\n\n\n\nConteo de Frecuencia por Clase:\ntipo_parto\nCesárea    0.509946\nNormal     0.490054\nName: count, dtype: float64\n\n\nSe visualiza las cantidad de datos nulos en el dataset.\n\n\nCode\n# Contar la cantidad de valores nulos por columna\nprint(\"--- Cantidad de valores nulos por columna ---\")\nvalores_nulos = nacidos_df.isnull().sum()\nprint(valores_nulos)\n\n# Contar la cantidad de valores con el texto 'Sin información' (que parece ser un valor nulo en este dataset)\nprint(\"\\n--- Cantidad de valores 'Sin información' por columna ---\")\nsin_informacion = (nacidos_df == 'Sin información').sum()\nprint(sin_informacion)\n\n\n--- Cantidad de valores nulos por columna ---\nsexo                 0\nanio_nacimiento      0\nmes_nacimiento       0\ndia_nacimiento       0\nfecha_nacimiento     0\ntalla                0\npeso                 0\nsem_gestacion        0\ntipo_parto           0\nlugar_ocurrido       0\narea_nacimiento      0\netnia                0\nestado_civil         0\nnivel_instruccion    0\ndtype: int64\n\n--- Cantidad de valores 'Sin información' por columna ---\nsexo                    0\nanio_nacimiento         0\nmes_nacimiento          0\ndia_nacimiento          0\nfecha_nacimiento        0\ntalla                6663\npeso                 6613\nsem_gestacion        6848\ntipo_parto              0\nlugar_ocurrido          0\narea_nacimiento         0\netnia                5611\nestado_civil         2352\nnivel_instruccion    2245\ndtype: int64\n\n\nLa graficas muestran que las variables no poseen una correlación uniforme. Es decir, no existe una correlación importante que explique el comportamiento de la variable objetivo (‘tipo_parto’)\n\n\nCode\nnumerical_columns = nacidos_df.select_dtypes('number').columns.tolist()\n\nalt.Chart(nacidos_df).mark_rect().encode(\n    alt.X(alt.repeat('column'),type='quantitative',bin=alt.Bin(maxbins=30)),\n    alt.Y(alt.repeat('row'),type='quantitative',bin=alt.Bin(maxbins=30)),\n    alt.Color('count()'),\n    alt.Tooltip('count()')\n).properties(\n    width=100,\n    height=100\n).repeat(\n    column=numerical_columns,\n    row=numerical_columns\n).resolve_scale(\n    color='independent'\n)"
  },
  {
    "objectID": "Regresion_Logistica.html#división-en-conjuntos-de-entrenamiento-y-prueba-train_test_split.",
    "href": "Regresion_Logistica.html#división-en-conjuntos-de-entrenamiento-y-prueba-train_test_split.",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Antes de realizar cualquier transformación en el dataset vamos a separar el grupo de entrenamiento y prueba:\n\n\nCode\n# Tratamos los valores 'tipo_parto'\nle = LabelEncoder()\nnacidos_df['tipo_parto_cod'] = le.fit_transform(nacidos_df['tipo_parto'].astype(str))\n\nprint(\"Mapeo de Codificación (Valor original : Valor numérico):\")\nmapeo_parto = dict(zip(le.classes_, le.transform(le.classes_)))\nprint(f\"*'tipo_parto_cod'--{mapeo_parto}\")\n\n\nMapeo de Codificación (Valor original : Valor numérico):\n*'tipo_parto_cod'--{'Cesárea': np.int64(0), 'Normal': np.int64(1)}\n\n\n\n\nCode\n# Definición de X e y\ny = nacidos_df['tipo_parto_cod']\nX = nacidos_df.drop(columns=['tipo_parto_cod', 'tipo_parto', 'fecha_nacimiento'])\n\n\nPreparamos dos pipelines para tratar los valores faltantes en las variables numericas y categoricas:\n\ncaracteristicas_mumericas = [‘talla’, ‘peso’, ‘sem_gestacion’, ‘anio_nacimiento’, ‘dia_nacimiento’]\ncaracteristicas_categoricas = [‘sexo’, ‘mes_nacimiento’, ‘lugar_ocurrido’, ‘area_nacimiento’, ‘etnia’, ‘estado_civil’, ‘nivel_instruccion’]"
  },
  {
    "objectID": "Regresion_Logistica.html#definición-y-entrenamiento-del-modelo-utilizando-pipeline.",
    "href": "Regresion_Logistica.html#definición-y-entrenamiento-del-modelo-utilizando-pipeline.",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Code\n# Definición de tipos de columnas numericas y categiricas\ncaracteristicas_mumericas = ['talla', 'peso', 'sem_gestacion', 'anio_nacimiento', 'dia_nacimiento']\ncaracteristicas_categoricas = ['sexo', 'mes_nacimiento', 'lugar_ocurrido', 'area_nacimiento', 'etnia', 'estado_civil', 'nivel_instruccion']\n\n# Pipeline para Datos Numericos\ntransform_numerica = Pipeline(steps=[\n    # Reemplazar la cadena 'Sin información' por NaN para imputación numérica\n    ('str_imputer', SimpleImputer(missing_values='Sin información', strategy='constant', fill_value=np.nan)),\n    # Imputar NaN con la mediana\n    ('num_imputer', SimpleImputer(strategy='median')),\n    # Escalar\n    ('scaler', StandardScaler())\n])\n\n# Pipeline para Datos Categoricos\ntransform_categorica = Pipeline(steps=[\n    # Reemplazar 'Sin información' con 'Desconocido'\n    ('str_imputer', SimpleImputer(missing_values='Sin información', strategy='constant', fill_value='Desconocido')),\n    # Imputar cualquier otro nulo con la moda\n    ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n    # Codificar con One-Hot Encoding\n    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n])\n\n# ColumnTransformer combinamos todos los pipelines\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', transform_numerica, caracteristicas_mumericas),\n        ('cat', transform_categorica, caracteristicas_categoricas)\n    ],\n    remainder='drop'    # Eliminamos todas las columnas que no van a ser tratadas por pipeline\n)\n\n\nUso de train_test_split para separar el dataset en entrenamiento y prueba:\n\n\nCode\n# --- División de Datos ---\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Pipeline Final (ColumnTransform + Modelo)\nlog_reg_pipeline = Pipeline(steps=[\n    ('preprocessor', preprocessor),\n    ('classifier', LogisticRegression(random_state=42, max_iter=2000))\n])\n\n# Entrenamiento\nlog_reg_pipeline.fit(X_train, y_train)\n\n\nPipeline(steps=[('preprocessor',\n                 ColumnTransformer(transformers=[('num',\n                                                  Pipeline(steps=[('str_imputer',\n                                                                   SimpleImputer(fill_value=nan,\n                                                                                 missing_values='Sin '\n                                                                                                'información',\n                                                                                 strategy='constant')),\n                                                                  ('num_imputer',\n                                                                   SimpleImputer(strategy='median')),\n                                                                  ('scaler',\n                                                                   StandardScaler())]),\n                                                  ['talla', 'peso',\n                                                   'sem_gestacion',\n                                                   'anio_nacimiento',\n                                                   'dia_nacimiento']),\n                                                 ('cat',\n                                                  Pipeline...\n                                                                                 missing_values='Sin '\n                                                                                                'información',\n                                                                                 strategy='constant')),\n                                                                  ('cat_imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('onehot',\n                                                                   OneHotEncoder(handle_unknown='ignore',\n                                                                                 sparse_output=False))]),\n                                                  ['sexo', 'mes_nacimiento',\n                                                   'lugar_ocurrido',\n                                                   'area_nacimiento', 'etnia',\n                                                   'estado_civil',\n                                                   'nivel_instruccion'])])),\n                ('classifier',\n                 LogisticRegression(max_iter=2000, random_state=42))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Pipeline?Documentation for PipelineiFitted\n        \n            \n                Parameters\n                \n\n\n\n\nsteps \n[('preprocessor', ...), ('classifier', ...)]\n\n\n\ntransform_input \nNone\n\n\n\nmemory \nNone\n\n\n\nverbose \nFalse\n\n\n\n\n            \n        \n    preprocessor: ColumnTransformer?Documentation for preprocessor: ColumnTransformer\n        \n            \n                Parameters\n                \n\n\n\n\ntransformers \n[('num', ...), ('cat', ...)]\n\n\n\nremainder \n'drop'\n\n\n\nsparse_threshold \n0.3\n\n\n\nn_jobs \nNone\n\n\n\ntransformer_weights \nNone\n\n\n\nverbose \nFalse\n\n\n\nverbose_feature_names_out \nTrue\n\n\n\nforce_int_remainder_cols \n'deprecated'\n\n\n\n\n            \n        \n    num['talla', 'peso', 'sem_gestacion', 'anio_nacimiento', 'dia_nacimiento']SimpleImputer?Documentation for SimpleImputer\n        \n            \n                Parameters\n                \n\n\n\n\nmissing_values \n'Sin información'\n\n\n\nstrategy \n'constant'\n\n\n\nfill_value \nnan\n\n\n\ncopy \nTrue\n\n\n\nadd_indicator \nFalse\n\n\n\nkeep_empty_features \nFalse\n\n\n\n\n            \n        \n    SimpleImputer?Documentation for SimpleImputer\n        \n            \n                Parameters\n                \n\n\n\n\nmissing_values \nnan\n\n\n\nstrategy \n'median'\n\n\n\nfill_value \nNone\n\n\n\ncopy \nTrue\n\n\n\nadd_indicator \nFalse\n\n\n\nkeep_empty_features \nFalse\n\n\n\n\n            \n        \n    StandardScaler?Documentation for StandardScaler\n        \n            \n                Parameters\n                \n\n\n\n\ncopy \nTrue\n\n\n\nwith_mean \nTrue\n\n\n\nwith_std \nTrue\n\n\n\n\n            \n        \n    cat['sexo', 'mes_nacimiento', 'lugar_ocurrido', 'area_nacimiento', 'etnia', 'estado_civil', 'nivel_instruccion']SimpleImputer?Documentation for SimpleImputer\n        \n            \n                Parameters\n                \n\n\n\n\nmissing_values \n'Sin información'\n\n\n\nstrategy \n'constant'\n\n\n\nfill_value \n'Desconocido'\n\n\n\ncopy \nTrue\n\n\n\nadd_indicator \nFalse\n\n\n\nkeep_empty_features \nFalse\n\n\n\n\n            \n        \n    SimpleImputer?Documentation for SimpleImputer\n        \n            \n                Parameters\n                \n\n\n\n\nmissing_values \nnan\n\n\n\nstrategy \n'most_frequent'\n\n\n\nfill_value \nNone\n\n\n\ncopy \nTrue\n\n\n\nadd_indicator \nFalse\n\n\n\nkeep_empty_features \nFalse\n\n\n\n\n            \n        \n    OneHotEncoder?Documentation for OneHotEncoder\n        \n            \n                Parameters\n                \n\n\n\n\ncategories \n'auto'\n\n\n\ndrop \nNone\n\n\n\nsparse_output \nFalse\n\n\n\ndtype \n&lt;class 'numpy.float64'&gt;\n\n\n\nhandle_unknown \n'ignore'\n\n\n\nmin_frequency \nNone\n\n\n\nmax_categories \nNone\n\n\n\nfeature_name_combiner \n'concat'\n\n\n\n\n            \n        \n    LogisticRegression?Documentation for LogisticRegression\n        \n            \n                Parameters\n                \n\n\n\n\npenalty \n'l2'\n\n\n\ndual \nFalse\n\n\n\ntol \n0.0001\n\n\n\nC \n1.0\n\n\n\nfit_intercept \nTrue\n\n\n\nintercept_scaling \n1\n\n\n\nclass_weight \nNone\n\n\n\nrandom_state \n42\n\n\n\nsolver \n'lbfgs'\n\n\n\nmax_iter \n2000\n\n\n\nmulti_class \n'deprecated'\n\n\n\nverbose \n0\n\n\n\nwarm_start \nFalse\n\n\n\nn_jobs \nNone\n\n\n\nl1_ratio \nNone"
  },
  {
    "objectID": "Regresion_Logistica.html#generación-de-predicciones.",
    "href": "Regresion_Logistica.html#generación-de-predicciones.",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Code\n# Predicción\ny_pred = log_reg_pipeline.predict(X_test)"
  },
  {
    "objectID": "Regresion_Logistica.html#evaluación-del-modelo-con-métricas-apropiadas.",
    "href": "Regresion_Logistica.html#evaluación-del-modelo-con-métricas-apropiadas.",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Code\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(f\"Precisión (Accuracy) en el conjunto de prueba: {accuracy:.4f}\")\n\nprint(\"Reporte de Clasificación:\")\nprint(classification_report(y_test, y_pred))\n\n\nPrecisión (Accuracy) en el conjunto de prueba: 0.7312\nReporte de Clasificación:\n              precision    recall  f1-score   support\n\n           0       0.81      0.62      0.70     22233\n           1       0.68      0.85      0.76     21365\n\n    accuracy                           0.73     43598\n   macro avg       0.74      0.73      0.73     43598\nweighted avg       0.75      0.73      0.73     43598"
  },
  {
    "objectID": "Regresion_Logistica.html#visualizaciones-e-interpretación-de-resultados",
    "href": "Regresion_Logistica.html#visualizaciones-e-interpretación-de-resultados",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Matriz de confución:\n\n\nCode\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\ncm = confusion_matrix(y_test, y_pred)\n\n# 'le' fue el LabelEncoder que codificó 'tipo_parto'\nclases = le.classes_ \n\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=True,          # Mostrar los valores numéricos en las celdas\n    fmt='d',             # Formato decimal (para números enteros)\n    cmap='Blues',        # Escala de color\n    xticklabels=clases,  # Etiquetas del eje X (Predichas)\n    yticklabels=clases,  # Etiquetas del eje Y (Reales)\n    cbar=False           \n)\nplt.title('Matriz de Confusión del Modelo de Regresión Logística', fontsize=14)\nplt.ylabel('Valores Reales (True Label)', fontsize=12)\nplt.xlabel('Valores Predichos (Predicted Label)', fontsize=12)\nplt.show()\n\n\n\n\n\n\n\n\n\nCurva ROC.\n\n\nCode\nfrom sklearn.metrics import roc_curve, auc\n\n# 1. Obtener las probabilidades de la clase positiva (Clase 1)\n# El método predict_proba devuelve las probabilidades para todas las clases.\n# Seleccionamos el índice [:, 1] que corresponde a la probabilidad de la clase positiva (1).\ny_probs = log_reg_pipeline.predict_proba(X_test)[:, 1]\n\n# 2. Calcular la Curva ROC\n# roc_curve devuelve: FPR (Tasa de Falsos Positivos), TPR (Tasa de Verdaderos Positivos), y Umbrales\nfpr, tpr, thresholds = roc_curve(y_test, y_probs)\n\n# 3. Calcular el Área Bajo la Curva (AUC)\n# El AUC es una métrica de resumen del rendimiento del clasificador.\nroc_auc = auc(fpr, tpr)\n\nprint(f\"Área Bajo la Curva (AUC): {roc_auc:.4f}\")\n\n\nÁrea Bajo la Curva (AUC): 0.7986\n\n\n\n\nCode\n# 4. Graficar la Curva ROC\nplt.figure(figsize=(8, 6))\n\n# Trazar la curva ROC principal\nplt.plot(\n    fpr, tpr, \n    color='darkorange', \n    lw=2, \n    label=f'Curva ROC (área = {roc_auc:.4f})'\n)\n\n# Trazar la línea de referencia (Clasificador Aleatorio)\nplt.plot(\n    [0, 1], [0, 1], \n    color='navy', \n    lw=2, \n    linestyle='--', \n    label='Clasificador Aleatorio (área = 0.50)'\n)\n\n# Configuración del gráfico\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Tasa de Falsos Positivos (FPR)', fontsize=12)\nplt.ylabel('Tasa de Verdaderos Positivos (TPR)', fontsize=12)\nplt.title('Curva ROC para Regresión Logística', fontsize=14)\nplt.legend(loc=\"lower right\")\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "Regresion_Logistica.html#resultados-obtenidos",
    "href": "Regresion_Logistica.html#resultados-obtenidos",
    "title": "Midterm Machine Learning",
    "section": "",
    "text": "Las métricas del ML definen al modelo como moderada:\n\nAccuracy de 0.7312 es moderado. Es decir, de cada 100 nacimientos, el modelo predijo correctamente el tipo de parto de 73 de ellos.\nPrecision de 0.74 mide el promedio de errores al cuadrado. Para contextualizar mejor este dato se observara Raíz del Error Cuadrático Medio (RMSE).\nRecall de 0.73 significa que e todos los nacimientos que realmente pertenecían a la Clase Positiva (Cesárea), el modelo logró identificar correctamente el 73%.\nF1 Score de 0.73 indica que el modelo ha logrado un equilibrio sólido entre el Recall y Precision.\nMatriz de confusión determina que existen 3272 Verdaderos negativo y 8446 falsos negativos. En el contexto de este dataset y el objetivo de predecir si las variables describen la varianza de la variable objetibo (Tipo de parto: Norma o Cesárea) existe un gran numero de predicciones erroneas.\n\n\n\n\nimage.png\n\n\n\nCurva ROC de 0.7986 significa que sí tomas¿mos al azar un nacimiento que resultó en la clase cesárea y un nacimiento que resultó normal, el modelo tiene una probabilidad del 79.86% de asignar una probabilidad más alta al nacimiento que realmente pertenece a cesárea.\n\n\n\n\nimage.png\n\n\nLa explicación de que la mayoria de metricas esten cerca del 0.73 se explica por el balance de la variable objetivo\ntipo_parto\n\nCesárea 50.9946 %\nNormal 49.0054 %"
  }
]